{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDL2020S_Assignment_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLPsPZQ1twS0",
        "colab_type": "text"
      },
      "source": [
        "*Team Members*:   \n",
        "Alisha Mehta, Matr.no: **221481**,  \n",
        "Ashish Soni, Matr.no: **221453**,  \n",
        "Peer Ahamad Shaik, matr.no: **221407**.  \n",
        "\n",
        "Exercise Group 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsOVzTXEF4ej",
        "colab_type": "text"
      },
      "source": [
        "**Multilayer Perceptron using TensorFlow 2.0**: Classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfgS66f-l0v-",
        "colab_type": "text"
      },
      "source": [
        "**MNIST dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuSaxgEIGQek",
        "colab_type": "text"
      },
      "source": [
        "- Importing Packages [tensorflow, numpy, matplotlib]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uiw_PLYlFvnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from __future__ import print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlivuenjGsXG",
        "colab_type": "text"
      },
      "source": [
        "- Loading data from keras.datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVmqplyrGfrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2uremCHHL7o",
        "colab_type": "code",
        "outputId": "dae6307a-e4c2-4017-baa2-17baa9017ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(\"No.of images for training:\", len(train_images))\n",
        "print(\"No.of images for testing:\", len(test_images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of images for training: 60000\n",
            "No.of images for testing: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPmwelEnphm1",
        "colab_type": "code",
        "outputId": "8049e58c-122f-45f8-8a2f-7514b5dc66ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.imshow(train_images[0], cmap =\"Accent\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6ba63cfba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNsK9kP0Gk1K",
        "colab_type": "text"
      },
      "source": [
        "- Declaring parameters for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d977iAXYH9tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Image parameters\n",
        "num_classes = len(np.unique(train_labels))\n",
        "num_features = np.shape(train_images[0])[0] * np.shape(train_images[0])[1]\n",
        "\n",
        "#Hyper-parameters\n",
        "learning_rate = 0.01\n",
        "training_steps = 3000\n",
        "batch_size = 256\n",
        "hiddenLayer_1_size = 128\n",
        "hiddenLayer_2_size = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_9XVSB5JWHB",
        "colab_type": "text"
      },
      "source": [
        "- Pre-processing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3m6okv9JVyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting data to float of 32 bit-size\n",
        "train_images = np.array(train_images, np.float32)\n",
        "test_images = np.array(test_images, np.float32)\n",
        "\n",
        "#ravel the data\n",
        "train_images = train_images.reshape([-1, num_features])\n",
        "test_images = test_images.reshape([-1,num_features])\n",
        "\n",
        "#Normalizing the data. (255 is the maximum value of a pixel here)\n",
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn-zRa-FLt_r",
        "colab_type": "text"
      },
      "source": [
        "- Using Special attribute tf.Initalizers.randomNormal(), to randomly get the Values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PJtLzV0L-Kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_normal = tf.initializers.RandomNormal()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iIYGW04MLpx",
        "colab_type": "text"
      },
      "source": [
        "- Weights and bias structure declarartion:\n",
        "  - storing values in dictionary, for easy access."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYjp1bftMJMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = {\n",
        "    'h1': tf.Variable(random_normal([num_features, hiddenLayer_1_size])),\n",
        "    'h2': tf.Variable(random_normal([hiddenLayer_1_size, hiddenLayer_2_size])),\n",
        "    'out': tf.Variable(random_normal([hiddenLayer_2_size, num_classes]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.zeros([hiddenLayer_1_size])),\n",
        "    'b2': tf.Variable(tf.zeros([hiddenLayer_2_size])),\n",
        "    'out': tf.Variable(tf.zeros([num_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi3fMaPYj8NP",
        "colab_type": "text"
      },
      "source": [
        "- Using tensorflow deafult API for batching the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nl39VwneXwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVhx1btiN9bp",
        "colab_type": "text"
      },
      "source": [
        "- **MLP MODEL**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxvte4GQN9IM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(x):\n",
        "  layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "  layer_1 = tf.nn.sigmoid(layer_1)\n",
        "\n",
        "  layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "  layer_2 = tf.nn.sigmoid(layer_2)\n",
        "\n",
        "  out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
        "  return tf.nn.softmax(out_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRO55EkUkQWl",
        "colab_type": "text"
      },
      "source": [
        "- Declaring a method called *cross_entropy* to calculate the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqHjX_MOeih6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy(y_pred, y_true):\n",
        "    # Encode label to a one hot vector.\n",
        "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
        "    # Clip prediction values to avoid log(0) error.\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
        "    # Compute cross-entropy.\n",
        "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjiSuI3Lknya",
        "colab_type": "text"
      },
      "source": [
        "- A small snippet for calculating the *accuracy*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrJwd-0gh0OO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(y_pred, y_true):\n",
        "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuBnnXYHh2LK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We are using stochastic gradient descent optimizer.\n",
        "optimizer = tf.optimizers.SGD(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42tZgx-wlDMu",
        "colab_type": "text"
      },
      "source": [
        "- Calculating gradients and updating the **weights** of the layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM5RKkcdQNtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimization process. \n",
        "def run_optimization(x, y):\n",
        "    with tf.GradientTape() as g:\n",
        "        pred = model(x)\n",
        "        loss = cross_entropy(pred, y)        \n",
        "    # Variables to update, i.e. trainable variables.\n",
        "    trainable_variables = list(weights.values()) + list(biases.values())\n",
        "    gradients = g.gradient(loss, trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "    del g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfHjGdWTlkTI",
        "colab_type": "text"
      },
      "source": [
        "- **Training Phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rFmierACfvB",
        "colab_type": "code",
        "outputId": "ff2190c9-71ac-4c10-a4e0-fc289e4cee6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
        "    # Run the optimization to update W and b values.\n",
        "    run_optimization(batch_x, batch_y)\n",
        "    if step % 100 == 0:\n",
        "        pred = model(batch_x)\n",
        "        loss = cross_entropy(pred, batch_y)\n",
        "        acc = accuracy(pred, batch_y)\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, acc))\n",
        "        #print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 424.19854736328125 Accuracy: 0.375\n",
            "Loss: 218.25265502929688 Accuracy: 0.68359375\n",
            "Loss: 116.95947265625 Accuracy: 0.8828125\n",
            "Loss: 107.33373260498047 Accuracy: 0.87109375\n",
            "Loss: 55.60253143310547 Accuracy: 0.93359375\n",
            "Loss: 47.41075134277344 Accuracy: 0.94921875\n",
            "Loss: 39.18633270263672 Accuracy: 0.95703125\n",
            "Loss: 47.71690368652344 Accuracy: 0.953125\n",
            "Loss: 32.49505615234375 Accuracy: 0.9765625\n",
            "Loss: 32.88903045654297 Accuracy: 0.96484375\n",
            "Loss: 20.520771026611328 Accuracy: 0.9765625\n",
            "Loss: 17.47661590576172 Accuracy: 0.984375\n",
            "Loss: 29.488393783569336 Accuracy: 0.96875\n",
            "Loss: 15.423981666564941 Accuracy: 0.98828125\n",
            "Loss: 15.409005165100098 Accuracy: 0.98046875\n",
            "Loss: 13.061232566833496 Accuracy: 0.984375\n",
            "Loss: 8.111684799194336 Accuracy: 0.9921875\n",
            "Loss: 21.216163635253906 Accuracy: 0.9765625\n",
            "Loss: 11.768924713134766 Accuracy: 0.98828125\n",
            "Loss: 10.912610054016113 Accuracy: 0.9921875\n",
            "Loss: 7.845883846282959 Accuracy: 0.99609375\n",
            "Loss: 6.299642562866211 Accuracy: 0.99609375\n",
            "Loss: 8.400581359863281 Accuracy: 0.9921875\n",
            "Loss: 4.533959865570068 Accuracy: 1.0\n",
            "Loss: 8.944976806640625 Accuracy: 0.98828125\n",
            "Loss: 9.285865783691406 Accuracy: 0.9921875\n",
            "Loss: 7.198172569274902 Accuracy: 0.9921875\n",
            "Loss: 10.982518196105957 Accuracy: 0.98828125\n",
            "Loss: 4.904059410095215 Accuracy: 0.99609375\n",
            "Loss: 4.392744064331055 Accuracy: 0.99609375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG6ZKqYqm73i",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy on test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIYprdUqgA31",
        "colab_type": "code",
        "outputId": "ae656779-7dde-49aa-a274-ccb64d3674b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_preds = model(test_images)\n",
        "acc = accuracy(test_preds, test_labels)\n",
        "print(\"Test Accuracy: %f\" % acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.973300\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}